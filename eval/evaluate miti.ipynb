{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:10.548985800Z",
     "start_time": "2024-05-05T07:43:04.062014300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.collection import Collection\n",
    "from pymongo.database import Database\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_env_path() -> Path:\n",
    "    return Path('..\\\\.env')\n",
    "\n",
    "\n",
    "load_dotenv(get_env_path())\n",
    "\n",
    "CONNECTION_STRING = f'mongodb://localhost:27017'\n",
    "CLIENT = MongoClient(CONNECTION_STRING)\n",
    "DB: Database = CLIENT['thesis']\n",
    "# noinspection SpellCheckingInspection\n",
    "TABLE_MITI: Collection = DB['miti']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:10.605988400Z",
     "start_time": "2024-05-05T07:43:10.549985500Z"
    }
   },
   "id": "f6aa2af6f0f7646",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_df_docs_poor = pd.DataFrame.from_records(list(TABLE_MITI.find(filter={'prompt.therapist_level': 'poor'})))\n",
    "_df_docs_mediocre = pd.DataFrame.from_records(list(TABLE_MITI.find(filter={'prompt.therapist_level': 'average'})))\n",
    "_df_docs_expert = pd.DataFrame.from_records(list(TABLE_MITI.find(filter={'prompt.therapist_level': 'expert'})))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:25.960486500Z",
     "start_time": "2024-05-05T07:43:24.892431400Z"
    }
   },
   "id": "b442e508e7c54bc0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id  _response_ms _retrieve_params api_version  \\\n0  658da31c864df60a8413a918          2978               {}        None   \n1  658da325864df60a8413a919          7516               {}        None   \n2  658da328864df60a8413a91a          3711               {}        None   \n3  658da32c864df60a8413a91b          3586               {}        None   \n4  658da32f864df60a8413a91c          2921               {}        None   \n\n  api_type organization api_base_override engine  \\\n0     None      stavnlp              None   None   \n1     None      stavnlp              None   None   \n2     None      stavnlp              None   None   \n3     None      stavnlp              None   None   \n4     None      stavnlp              None   None   \n\n                                           _previous  \\\n0  {'id': 'chatcmpl-8anazJeqWBWib6l3EndfC2bW1jbZe...   \n1  {'id': 'chatcmpl-8anb3ZkRHa43gWZonDx0ML2GXALMo...   \n2  {'id': 'chatcmpl-8anbBf6I7cwMtLZ5vzFePmJxN8FW7...   \n3  {'id': 'chatcmpl-8anbFJwK65fHMzbOYIRljGDsG2s6j...   \n4  {'id': 'chatcmpl-8anbJs0EcEMBV0ffWwfBxvh3env6Q...   \n\n                                              prompt     timestamp  \n0  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n1  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n2  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n3  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n4  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>_response_ms</th>\n      <th>_retrieve_params</th>\n      <th>api_version</th>\n      <th>api_type</th>\n      <th>organization</th>\n      <th>api_base_override</th>\n      <th>engine</th>\n      <th>_previous</th>\n      <th>prompt</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>658da31c864df60a8413a918</td>\n      <td>2978</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anazJeqWBWib6l3EndfC2bW1jbZe...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>658da325864df60a8413a919</td>\n      <td>7516</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anb3ZkRHa43gWZonDx0ML2GXALMo...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>658da328864df60a8413a91a</td>\n      <td>3711</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anbBf6I7cwMtLZ5vzFePmJxN8FW7...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>658da32c864df60a8413a91b</td>\n      <td>3586</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anbFJwK65fHMzbOYIRljGDsG2s6j...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>658da32f864df60a8413a91c</td>\n      <td>2921</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anbJs0EcEMBV0ffWwfBxvh3env6Q...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_docs_poor.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:26.000520300Z",
     "start_time": "2024-05-05T07:43:25.960486500Z"
    }
   },
   "id": "58b3cb25866ca8a2",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id  _response_ms _retrieve_params api_version  \\\n0  658da363864df60a8413a92a          2712               {}        None   \n1  658da367864df60a8413a92b          4039               {}        None   \n2  658da36e864df60a8413a92c          6111               {}        None   \n3  658da373864df60a8413a92d          5365               {}        None   \n4  658da377864df60a8413a92e          3325               {}        None   \n\n  api_type organization api_base_override engine  \\\n0     None      stavnlp              None   None   \n1     None      stavnlp              None   None   \n2     None      stavnlp              None   None   \n3     None      stavnlp              None   None   \n4     None      stavnlp              None   None   \n\n                                           _previous  \\\n0  {'id': 'chatcmpl-8anc998YZB1XSK3a5kZUVOKu8gAgD...   \n1  {'id': 'chatcmpl-8ancCQhREC92zfrNnWfr4yTfuIQGU...   \n2  {'id': 'chatcmpl-8ancG8w4QFbGHbR7ZmrcaygwinZVJ...   \n3  {'id': 'chatcmpl-8ancMFsUv752NBJankIjYpzhTGAZV...   \n4  {'id': 'chatcmpl-8ancSUOXMEylIYSX5521HEtGZofsR...   \n\n                                              prompt     timestamp  \n0  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n1  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n2  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n3  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  \n4  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>_response_ms</th>\n      <th>_retrieve_params</th>\n      <th>api_version</th>\n      <th>api_type</th>\n      <th>organization</th>\n      <th>api_base_override</th>\n      <th>engine</th>\n      <th>_previous</th>\n      <th>prompt</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>658da363864df60a8413a92a</td>\n      <td>2712</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anc998YZB1XSK3a5kZUVOKu8gAgD...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>658da367864df60a8413a92b</td>\n      <td>4039</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8ancCQhREC92zfrNnWfr4yTfuIQGU...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>658da36e864df60a8413a92c</td>\n      <td>6111</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8ancG8w4QFbGHbR7ZmrcaygwinZVJ...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>658da373864df60a8413a92d</td>\n      <td>5365</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8ancMFsUv752NBJankIjYpzhTGAZV...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>658da377864df60a8413a92e</td>\n      <td>3325</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8ancSUOXMEylIYSX5521HEtGZofsR...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_docs_mediocre.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:27.216205700Z",
     "start_time": "2024-05-05T07:43:27.171464500Z"
    }
   },
   "id": "c2d77d6be39f82eb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id  _response_ms _retrieve_params api_version  \\\n0  658da3ab864df60a8413a93c          2766               {}        None   \n1  658da3b2864df60a8413a93d          6350               {}        None   \n2  658da3b6864df60a8413a93e          3665               {}        None   \n3  658da3ba864df60a8413a93f          3767               {}        None   \n4  658da3bf864df60a8413a940          5490               {}        None   \n\n  api_type organization api_base_override engine  \\\n0     None      stavnlp              None   None   \n1     None      stavnlp              None   None   \n2     None      stavnlp              None   None   \n3     None      stavnlp              None   None   \n4     None      stavnlp              None   None   \n\n                                           _previous  \\\n0  {'id': 'chatcmpl-8andJ6r0SqsHQLGIlhlb0AlNxLPq0...   \n1  {'id': 'chatcmpl-8andMWEhZ8ieM3u2IaANc7W6x1BA6...   \n2  {'id': 'chatcmpl-8andS21da6im3DIRkjOt6z0GNNYzY...   \n3  {'id': 'chatcmpl-8andWhV0CsIv9JmJNqqTvvGQisAVa...   \n4  {'id': 'chatcmpl-8anda5QkpfV5Yxx4e7eFgFawZF2C8...   \n\n                                              prompt     timestamp  \\\n0  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09   \n1  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09   \n2  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09   \n3  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09   \n4  {'model': 'gpt-3.5-turbo-1106', 'request_timeo...  1.703781e+09   \n\n                                              llama2  \n0  {'finetuning/miti_alexander_street/meta-llama-...  \n1  {'finetuning/miti_alexander_street/meta-llama-...  \n2  {'finetuning/miti_alexander_street/meta-llama-...  \n3  {'finetuning/miti_alexander_street/meta-llama-...  \n4  {'finetuning/miti_alexander_street/meta-llama-...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>_response_ms</th>\n      <th>_retrieve_params</th>\n      <th>api_version</th>\n      <th>api_type</th>\n      <th>organization</th>\n      <th>api_base_override</th>\n      <th>engine</th>\n      <th>_previous</th>\n      <th>prompt</th>\n      <th>timestamp</th>\n      <th>llama2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>658da3ab864df60a8413a93c</td>\n      <td>2766</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8andJ6r0SqsHQLGIlhlb0AlNxLPq0...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n      <td>{'finetuning/miti_alexander_street/meta-llama-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>658da3b2864df60a8413a93d</td>\n      <td>6350</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8andMWEhZ8ieM3u2IaANc7W6x1BA6...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n      <td>{'finetuning/miti_alexander_street/meta-llama-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>658da3b6864df60a8413a93e</td>\n      <td>3665</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8andS21da6im3DIRkjOt6z0GNNYzY...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n      <td>{'finetuning/miti_alexander_street/meta-llama-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>658da3ba864df60a8413a93f</td>\n      <td>3767</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8andWhV0CsIv9JmJNqqTvvGQisAVa...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n      <td>{'finetuning/miti_alexander_street/meta-llama-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>658da3bf864df60a8413a940</td>\n      <td>5490</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>stavnlp</td>\n      <td>None</td>\n      <td>None</td>\n      <td>{'id': 'chatcmpl-8anda5QkpfV5Yxx4e7eFgFawZF2C8...</td>\n      <td>{'model': 'gpt-3.5-turbo-1106', 'request_timeo...</td>\n      <td>1.703781e+09</td>\n      <td>{'finetuning/miti_alexander_street/meta-llama-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_docs_expert.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:43:27.702718800Z",
     "start_time": "2024-05-05T07:43:27.680691Z"
    }
   },
   "id": "c3310af3570212ba",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for _df_docs in [_df_docs_poor, _df_docs_mediocre, _df_docs_expert]:\n",
    "    _df_docs['filename'] = _df_docs['prompt'].apply(lambda _x: _x['filename'])\n",
    "    _df_docs['count_messages'] = _df_docs['prompt'].apply(lambda _x: len(_x['messages']))\n",
    "    _df_docs['therapist_level'] = _df_docs['prompt'].apply(lambda _x: _x['therapist_level'])\n",
    "    _df_docs['predicted'] = _df_docs['_previous'].apply(lambda _x: _x['choices'][0]['message']['content'])\n",
    "    _df_docs['reference'] = _df_docs['prompt'].apply(lambda _x: _x['true_response'])\n",
    "    _df_docs['predicted_words_count'] = _df_docs['predicted'].apply(lambda _x: len(_x.split()))\n",
    "    _df_docs['reference_words_count'] = _df_docs['reference'].apply(lambda _x: len(_x.split()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:46:35.378957800Z",
     "start_time": "2024-05-05T07:46:35.292447700Z"
    }
   },
   "id": "72f1c865c2df771",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_cols = ['therapist_level', 'predicted', 'reference']\n",
    "pd.concat([_df_docs_poor[_cols], _df_docs_mediocre[_cols], _df_docs_expert[_cols]]).to_csv('data to eval mauve.csv',\n",
    "                                                                                           index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:49:19.679034400Z",
     "start_time": "2024-05-05T07:49:19.603525600Z"
    }
   },
   "id": "e628a0ffcf23d492",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\stav3\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\1dfb731fe2846298242021b3971e53cd2b22233cb0c4fdd87721b208630c396f\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "_bleu = evaluate.load(\"bleu\")\n",
    "_rouge = evaluate.load(\"rouge\")\n",
    "_meteor = evaluate.load(\"meteor\")\n",
    "_bertscore = evaluate.load(\"bertscore\", device='cuda:0')\n",
    "_frugalscore = evaluate.load(\"frugalscore\", \"moussaKam/frugalscore_medium_bert-base_mover-score\")\n",
    "_google_bleu = evaluate.load(\"google_bleu\")\n",
    "_bleurt = evaluate.load(\"bleurt\", module_type=\"metric\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:36:24.358747400Z",
     "start_time": "2024-05-03T07:36:12.882410800Z"
    }
   },
   "id": "386819a00a762148",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6652 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45e0275ad8484182bc1cec2e4e018017"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/416 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  33%|███▎      | 1/3 [03:43<07:26, 223.50s/it]Parameter 'function'=<function FRUGALSCORE._compute.<locals>.tokenize_function at 0x000001FA126A0550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "WARNING:datasets.fingerprint:Parameter 'function'=<function FRUGALSCORE._compute.<locals>.tokenize_function at 0x000001FA126A0550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6652 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20941bf1d26e4679b2b2478267946075"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/416 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  67%|██████▋   | 2/3 [07:32<03:46, 226.53s/it]"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6652 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "452a992ef9d748528c661dc163110fd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/416 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [11:09<00:00, 223.29s/it]\n"
     ]
    }
   ],
   "source": [
    "_dfs = {\n",
    "    'poor': _df_docs_poor,\n",
    "    'mediocre': _df_docs_mediocre,\n",
    "    'expert': _df_docs_expert\n",
    "}\n",
    "\n",
    "_eval = defaultdict(defaultdict)\n",
    "\n",
    "for _k, _df in tqdm(_dfs.items(), desc='Evaluating'):\n",
    "    _predictions = list(_df['predicted'])\n",
    "    _references = list(_df['reference'])\n",
    "\n",
    "    _eval[_k]['predicted_utterances_count'] = len(_df)\n",
    "    _eval[_k]['predicted_words_count_mean'] = np.mean(_df['predicted_words_count'])\n",
    "    _eval[_k]['predicted_words_count_std'] = np.std(_df['predicted_words_count'])\n",
    "    _eval[_k]['reference_words_count_mean'] = np.mean(_df['reference_words_count'])\n",
    "    _eval[_k]['reference_words_count_std'] = np.std(_df['reference_words_count'])\n",
    "\n",
    "    _eval[_k]['bleu'] = _bleu.compute(predictions=_predictions, references=_references)\n",
    "    _eval[_k]['rouge'] = _rouge.compute(predictions=_predictions, references=_references)\n",
    "    _eval[_k]['meteor'] = _meteor.compute(predictions=_predictions, references=_references)\n",
    "    _eval[_k]['bertscore'] = _bertscore.compute(predictions=_predictions, references=_references, lang=\"en\")\n",
    "    _eval[_k]['frugalscore'] = _frugalscore.compute(predictions=_predictions, references=[_x[0] for _x in _references],\n",
    "                                                    batch_size=16, max_length=64, device=\"gpu\")\n",
    "    _eval[_k]['google_bleu'] = _google_bleu.compute(predictions=_predictions, references=_references)\n",
    "    _eval[_k]['bleurt'] = _bleurt.compute(predictions=_predictions, references=[_x[0] for _x in _references])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:47:34.247016500Z",
     "start_time": "2024-05-03T07:36:24.360121400Z"
    }
   },
   "id": "eb2eb32f98371e3d",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          predicted_utterances_count  predicted_words_count_mean  \\\npoor                            6652                   32.564943   \nmediocre                        6652                   30.733464   \nexpert                          6652                   32.985869   \n\n          predicted_words_count_std  reference_words_count_mean  \\\npoor                      25.818824                   25.904991   \nmediocre                  23.318381                   25.904991   \nexpert                    23.534780                   25.904991   \n\n          reference_words_count_std  \\\npoor                      29.444664   \nmediocre                  29.444664   \nexpert                    29.444664   \n\n                                                       bleu  \\\npoor      {'bleu': 0.014572493807103633, 'precisions': [...   \nmediocre  {'bleu': 0.015430180836158321, 'precisions': [...   \nexpert    {'bleu': 0.015577436781898855, 'precisions': [...   \n\n                                                      rouge  \\\npoor      {'rouge1': 0.17350544135109638, 'rouge2': 0.02...   \nmediocre  {'rouge1': 0.17817508589510853, 'rouge2': 0.02...   \nexpert    {'rouge1': 0.17897434545731436, 'rouge2': 0.03...   \n\n                                   meteor  \\\npoor      {'meteor': 0.16170356837938385}   \nmediocre  {'meteor': 0.16146440462682232}   \nexpert    {'meteor': 0.16763884330223833}   \n\n                                                  bertscore  \\\npoor      {'precision': [0.8835488557815552, 0.842295408...   \nmediocre  {'precision': [0.8938807249069214, 0.875382423...   \nexpert    {'precision': [0.9014953970909119, 0.857551753...   \n\n                                                frugalscore  \\\npoor      {'scores': [-0.32910156, -0.2919922, -0.329101...   \nmediocre  {'scores': [-0.3552246, -0.2841797, -0.3276367...   \nexpert    {'scores': [-0.33984375, -0.2944336, -0.329101...   \n\n                                    google_bleu  \\\npoor      {'google_bleu': 0.043398185133269394}   \nmediocre    {'google_bleu': 0.0446229537624029}   \nexpert    {'google_bleu': 0.044768307157906424}   \n\n                                                     bleurt  \npoor      {'scores': [-2.2996315956115723, -2.1110601425...  \nmediocre  {'scores': [-2.424213171005249, -2.41297531127...  \nexpert    {'scores': [-1.892256498336792, -1.99957525730...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted_utterances_count</th>\n      <th>predicted_words_count_mean</th>\n      <th>predicted_words_count_std</th>\n      <th>reference_words_count_mean</th>\n      <th>reference_words_count_std</th>\n      <th>bleu</th>\n      <th>rouge</th>\n      <th>meteor</th>\n      <th>bertscore</th>\n      <th>frugalscore</th>\n      <th>google_bleu</th>\n      <th>bleurt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>poor</th>\n      <td>6652</td>\n      <td>32.564943</td>\n      <td>25.818824</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'bleu': 0.014572493807103633, 'precisions': [...</td>\n      <td>{'rouge1': 0.17350544135109638, 'rouge2': 0.02...</td>\n      <td>{'meteor': 0.16170356837938385}</td>\n      <td>{'precision': [0.8835488557815552, 0.842295408...</td>\n      <td>{'scores': [-0.32910156, -0.2919922, -0.329101...</td>\n      <td>{'google_bleu': 0.043398185133269394}</td>\n      <td>{'scores': [-2.2996315956115723, -2.1110601425...</td>\n    </tr>\n    <tr>\n      <th>mediocre</th>\n      <td>6652</td>\n      <td>30.733464</td>\n      <td>23.318381</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'bleu': 0.015430180836158321, 'precisions': [...</td>\n      <td>{'rouge1': 0.17817508589510853, 'rouge2': 0.02...</td>\n      <td>{'meteor': 0.16146440462682232}</td>\n      <td>{'precision': [0.8938807249069214, 0.875382423...</td>\n      <td>{'scores': [-0.3552246, -0.2841797, -0.3276367...</td>\n      <td>{'google_bleu': 0.0446229537624029}</td>\n      <td>{'scores': [-2.424213171005249, -2.41297531127...</td>\n    </tr>\n    <tr>\n      <th>expert</th>\n      <td>6652</td>\n      <td>32.985869</td>\n      <td>23.534780</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'bleu': 0.015577436781898855, 'precisions': [...</td>\n      <td>{'rouge1': 0.17897434545731436, 'rouge2': 0.03...</td>\n      <td>{'meteor': 0.16763884330223833}</td>\n      <td>{'precision': [0.9014953970909119, 0.857551753...</td>\n      <td>{'scores': [-0.33984375, -0.2944336, -0.329101...</td>\n      <td>{'google_bleu': 0.044768307157906424}</td>\n      <td>{'scores': [-1.892256498336792, -1.99957525730...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_result = pd.DataFrame.from_dict(_eval, orient='index')\n",
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:51:27.212524200Z",
     "start_time": "2024-05-03T07:51:27.193504300Z"
    }
   },
   "id": "61a0d424e71a9c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          predicted_words_count_std  predicted_utterances_count  \\\npoor                      25.818824                        6652   \nmediocre                  23.318381                        6652   \nexpert                    23.534780                        6652   \n\n          predicted_words_count_mean  \\\npoor                       32.564943   \nmediocre                   30.733464   \nexpert                     32.985869   \n\n                                                       bleu  \\\npoor      {'bleu': 0.014572493807103633, 'precisions': [...   \nmediocre  {'bleu': 0.015430180836158321, 'precisions': [...   \nexpert    {'bleu': 0.015577436781898855, 'precisions': [...   \n\n          reference_words_count_mean  reference_words_count_std  \\\npoor                       25.904991                  29.444664   \nmediocre                   25.904991                  29.444664   \nexpert                     25.904991                  29.444664   \n\n                                                  bertscore  \\\npoor      {'precision': [0.8835488557815552, 0.842295408...   \nmediocre  {'precision': [0.8938807249069214, 0.875382423...   \nexpert    {'precision': [0.9014953970909119, 0.857551753...   \n\n                                                      rouge  \\\npoor      {'rouge1': 0.17350544135109638, 'rouge2': 0.02...   \nmediocre  {'rouge1': 0.17817508589510853, 'rouge2': 0.02...   \nexpert    {'rouge1': 0.17897434545731436, 'rouge2': 0.03...   \n\n                                   meteor  \\\npoor      {'meteor': 0.16170356837938385}   \nmediocre  {'meteor': 0.16146440462682232}   \nexpert    {'meteor': 0.16763884330223833}   \n\n                                                     bleurt  \\\npoor      {'scores': [-2.2996315956115723, -2.1110601425...   \nmediocre  {'scores': [-2.424213171005249, -2.41297531127...   \nexpert    {'scores': [-1.892256498336792, -1.99957525730...   \n\n                                                frugalscore  \\\npoor      {'scores': [-0.32910156, -0.2919922, -0.329101...   \nmediocre  {'scores': [-0.3552246, -0.2841797, -0.3276367...   \nexpert    {'scores': [-0.33984375, -0.2944336, -0.329101...   \n\n                                    google_bleu  \npoor      {'google_bleu': 0.043398185133269394}  \nmediocre    {'google_bleu': 0.0446229537624029}  \nexpert    {'google_bleu': 0.044768307157906424}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted_words_count_std</th>\n      <th>predicted_utterances_count</th>\n      <th>predicted_words_count_mean</th>\n      <th>bleu</th>\n      <th>reference_words_count_mean</th>\n      <th>reference_words_count_std</th>\n      <th>bertscore</th>\n      <th>rouge</th>\n      <th>meteor</th>\n      <th>bleurt</th>\n      <th>frugalscore</th>\n      <th>google_bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>poor</th>\n      <td>25.818824</td>\n      <td>6652</td>\n      <td>32.564943</td>\n      <td>{'bleu': 0.014572493807103633, 'precisions': [...</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'precision': [0.8835488557815552, 0.842295408...</td>\n      <td>{'rouge1': 0.17350544135109638, 'rouge2': 0.02...</td>\n      <td>{'meteor': 0.16170356837938385}</td>\n      <td>{'scores': [-2.2996315956115723, -2.1110601425...</td>\n      <td>{'scores': [-0.32910156, -0.2919922, -0.329101...</td>\n      <td>{'google_bleu': 0.043398185133269394}</td>\n    </tr>\n    <tr>\n      <th>mediocre</th>\n      <td>23.318381</td>\n      <td>6652</td>\n      <td>30.733464</td>\n      <td>{'bleu': 0.015430180836158321, 'precisions': [...</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'precision': [0.8938807249069214, 0.875382423...</td>\n      <td>{'rouge1': 0.17817508589510853, 'rouge2': 0.02...</td>\n      <td>{'meteor': 0.16146440462682232}</td>\n      <td>{'scores': [-2.424213171005249, -2.41297531127...</td>\n      <td>{'scores': [-0.3552246, -0.2841797, -0.3276367...</td>\n      <td>{'google_bleu': 0.0446229537624029}</td>\n    </tr>\n    <tr>\n      <th>expert</th>\n      <td>23.534780</td>\n      <td>6652</td>\n      <td>32.985869</td>\n      <td>{'bleu': 0.015577436781898855, 'precisions': [...</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'precision': [0.9014953970909119, 0.857551753...</td>\n      <td>{'rouge1': 0.17897434545731436, 'rouge2': 0.03...</td>\n      <td>{'meteor': 0.16763884330223833}</td>\n      <td>{'scores': [-1.892256498336792, -1.99957525730...</td>\n      <td>{'scores': [-0.33984375, -0.2944336, -0.329101...</td>\n      <td>{'google_bleu': 0.044768307157906424}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_list = _df_result.columns.tolist()\n",
    "\n",
    "for _i in range(0, len(_list), 3):\n",
    "    _list[_i], _list[_i + 1], _list[_i + 2] = _list[_i + 2], _list[_i], _list[_i + 1]\n",
    "\n",
    "_df_result = _df_result[_list]\n",
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:51:34.901658Z",
     "start_time": "2024-05-03T07:51:34.872901Z"
    }
   },
   "id": "d31fbaa73f7b5e80",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bertscore_{_k}_mean'] = _df_result['bertscore'].apply(lambda _x: np.mean(_x[_k]))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bertscore_{_k}_mean'] = _df_result['bertscore'].apply(lambda _x: np.mean(_x[_k]))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bertscore_{_k}_mean'] = _df_result['bertscore'].apply(lambda _x: np.mean(_x[_k]))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bertscore_{_k}_std'] = _df_result['bertscore'].apply(lambda _x: np.std(_x[_k]))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'frugalscore_{_k}_mean'] = _df_result['frugalscore'].apply(lambda _x: np.mean(_x['scores']))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'frugalscore_{_k}_std'] = _df_result['frugalscore'].apply(lambda _x: np.std(_x['scores']))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bleurt_{_k}_mean'] = _df_result['bleurt'].apply(lambda _x: np.mean(_x['scores']))\n",
      "C:\\Users\\stav3\\AppData\\Local\\Temp\\ipykernel_2828\\2570678276.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df_result[f'bleurt_{_k}_std'] = _df_result['bleurt'].apply(lambda _x: np.std(_x['scores']))\n"
     ]
    }
   ],
   "source": [
    "for _k in ['precision', 'recall', 'f1']:\n",
    "    _df_result[f'bertscore_{_k}_mean'] = _df_result['bertscore'].apply(lambda _x: np.mean(_x[_k]))\n",
    "_df_result[f'bertscore_{_k}_std'] = _df_result['bertscore'].apply(lambda _x: np.std(_x[_k]))\n",
    "\n",
    "_df_result[f'frugalscore_{_k}_mean'] = _df_result['frugalscore'].apply(lambda _x: np.mean(_x['scores']))\n",
    "_df_result[f'frugalscore_{_k}_std'] = _df_result['frugalscore'].apply(lambda _x: np.std(_x['scores']))\n",
    "\n",
    "_df_result[f'bleurt_{_k}_mean'] = _df_result['bleurt'].apply(lambda _x: np.mean(_x['scores']))\n",
    "_df_result[f'bleurt_{_k}_std'] = _df_result['bleurt'].apply(lambda _x: np.std(_x['scores']))\n",
    "_df_result = _df_result[sorted(_df_result.columns.tolist())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:51:37.720195300Z",
     "start_time": "2024-05-03T07:51:37.697741300Z"
    }
   },
   "id": "fdd4b5d33d804db",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  bertscore  \\\npoor      {'precision': [0.8835488557815552, 0.842295408...   \nmediocre  {'precision': [0.8938807249069214, 0.875382423...   \nexpert    {'precision': [0.9014953970909119, 0.857551753...   \n\n          bertscore_f1_mean  bertscore_f1_std  bertscore_precision_mean  \\\npoor               0.849103          0.026098                  0.848257   \nmediocre           0.849891          0.025526                  0.849094   \nexpert             0.849881          0.025005                  0.848371   \n\n          bertscore_recall_mean  \\\npoor                   0.850691   \nmediocre               0.851425   \nexpert                 0.852070   \n\n                                                       bleu  \\\npoor      {'bleu': 0.014572493807103633, 'precisions': [...   \nmediocre  {'bleu': 0.015430180836158321, 'precisions': [...   \nexpert    {'bleu': 0.015577436781898855, 'precisions': [...   \n\n                                                     bleurt  bleurt_f1_mean  \\\npoor      {'scores': [-2.2996315956115723, -2.1110601425...       -1.938766   \nmediocre  {'scores': [-2.424213171005249, -2.41297531127...       -1.979516   \nexpert    {'scores': [-1.892256498336792, -1.99957525730...       -1.997368   \n\n          bleurt_f1_std                                        frugalscore  \\\npoor           0.442929  {'scores': [-0.32910156, -0.2919922, -0.329101...   \nmediocre       0.420758  {'scores': [-0.3552246, -0.2841797, -0.3276367...   \nexpert         0.367337  {'scores': [-0.33984375, -0.2944336, -0.329101...   \n\n          frugalscore_f1_mean  frugalscore_f1_std  \\\npoor                -0.297933            0.056519   \nmediocre            -0.299029            0.054311   \nexpert              -0.302099            0.048178   \n\n                                    google_bleu  \\\npoor      {'google_bleu': 0.043398185133269394}   \nmediocre    {'google_bleu': 0.0446229537624029}   \nexpert    {'google_bleu': 0.044768307157906424}   \n\n                                   meteor  predicted_utterances_count  \\\npoor      {'meteor': 0.16170356837938385}                        6652   \nmediocre  {'meteor': 0.16146440462682232}                        6652   \nexpert    {'meteor': 0.16763884330223833}                        6652   \n\n          predicted_words_count_mean  predicted_words_count_std  \\\npoor                       32.564943                  25.818824   \nmediocre                   30.733464                  23.318381   \nexpert                     32.985869                  23.534780   \n\n          reference_words_count_mean  reference_words_count_std  \\\npoor                       25.904991                  29.444664   \nmediocre                   25.904991                  29.444664   \nexpert                     25.904991                  29.444664   \n\n                                                      rouge  \npoor      {'rouge1': 0.17350544135109638, 'rouge2': 0.02...  \nmediocre  {'rouge1': 0.17817508589510853, 'rouge2': 0.02...  \nexpert    {'rouge1': 0.17897434545731436, 'rouge2': 0.03...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bertscore</th>\n      <th>bertscore_f1_mean</th>\n      <th>bertscore_f1_std</th>\n      <th>bertscore_precision_mean</th>\n      <th>bertscore_recall_mean</th>\n      <th>bleu</th>\n      <th>bleurt</th>\n      <th>bleurt_f1_mean</th>\n      <th>bleurt_f1_std</th>\n      <th>frugalscore</th>\n      <th>frugalscore_f1_mean</th>\n      <th>frugalscore_f1_std</th>\n      <th>google_bleu</th>\n      <th>meteor</th>\n      <th>predicted_utterances_count</th>\n      <th>predicted_words_count_mean</th>\n      <th>predicted_words_count_std</th>\n      <th>reference_words_count_mean</th>\n      <th>reference_words_count_std</th>\n      <th>rouge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>poor</th>\n      <td>{'precision': [0.8835488557815552, 0.842295408...</td>\n      <td>0.849103</td>\n      <td>0.026098</td>\n      <td>0.848257</td>\n      <td>0.850691</td>\n      <td>{'bleu': 0.014572493807103633, 'precisions': [...</td>\n      <td>{'scores': [-2.2996315956115723, -2.1110601425...</td>\n      <td>-1.938766</td>\n      <td>0.442929</td>\n      <td>{'scores': [-0.32910156, -0.2919922, -0.329101...</td>\n      <td>-0.297933</td>\n      <td>0.056519</td>\n      <td>{'google_bleu': 0.043398185133269394}</td>\n      <td>{'meteor': 0.16170356837938385}</td>\n      <td>6652</td>\n      <td>32.564943</td>\n      <td>25.818824</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.17350544135109638, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>mediocre</th>\n      <td>{'precision': [0.8938807249069214, 0.875382423...</td>\n      <td>0.849891</td>\n      <td>0.025526</td>\n      <td>0.849094</td>\n      <td>0.851425</td>\n      <td>{'bleu': 0.015430180836158321, 'precisions': [...</td>\n      <td>{'scores': [-2.424213171005249, -2.41297531127...</td>\n      <td>-1.979516</td>\n      <td>0.420758</td>\n      <td>{'scores': [-0.3552246, -0.2841797, -0.3276367...</td>\n      <td>-0.299029</td>\n      <td>0.054311</td>\n      <td>{'google_bleu': 0.0446229537624029}</td>\n      <td>{'meteor': 0.16146440462682232}</td>\n      <td>6652</td>\n      <td>30.733464</td>\n      <td>23.318381</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.17817508589510853, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>expert</th>\n      <td>{'precision': [0.9014953970909119, 0.857551753...</td>\n      <td>0.849881</td>\n      <td>0.025005</td>\n      <td>0.848371</td>\n      <td>0.852070</td>\n      <td>{'bleu': 0.015577436781898855, 'precisions': [...</td>\n      <td>{'scores': [-1.892256498336792, -1.99957525730...</td>\n      <td>-1.997368</td>\n      <td>0.367337</td>\n      <td>{'scores': [-0.33984375, -0.2944336, -0.329101...</td>\n      <td>-0.302099</td>\n      <td>0.048178</td>\n      <td>{'google_bleu': 0.044768307157906424}</td>\n      <td>{'meteor': 0.16763884330223833}</td>\n      <td>6652</td>\n      <td>32.985869</td>\n      <td>23.534780</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.17897434545731436, 'rouge2': 0.03...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T07:51:39.431993900Z",
     "start_time": "2024-05-03T07:51:39.405080700Z"
    }
   },
   "id": "dc89310aeb973b70",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
