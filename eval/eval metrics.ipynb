{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:05:13.831424600Z",
     "start_time": "2024-02-19T11:05:08.264809600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.collection import Collection\n",
    "from pymongo.database import Database\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_env_path() -> Path:\n",
    "    return Path('..\\\\.env')\n",
    "\n",
    "\n",
    "load_dotenv(get_env_path())\n",
    "\n",
    "CONNECTION_STRING = f'mongodb://localhost:27017'\n",
    "CLIENT = MongoClient(CONNECTION_STRING)\n",
    "DB: Database = CLIENT['thesis']\n",
    "# noinspection SpellCheckingInspection\n",
    "TABLE_MITI: Collection = DB['miti']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:05:13.846424Z",
     "start_time": "2024-02-19T11:05:13.832425800Z"
    }
   },
   "id": "1a62868d7b04bdea",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_df_existing_evals = pd.read_csv('llama2_eval.csv', index_col=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:05:13.894442300Z",
     "start_time": "2024-02-19T11:05:13.847424100Z"
    }
   },
   "id": "c2ae3c8352f02dd4",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              Model  \\\n0           0  finetuning/miti_alexander_street/meta-llama-Ll...   \n1           1  finetuning/alexander_street_small/meta-llama-L...   \n2           2  finetuning/alexander_street_large/meta-llama-L...   \n3           3                      meta-llama/Llama-2-7b-chat-hf   \n4           4  finetuning/alexander_street_large/meta-llama-L...   \n5           5  finetuning/alexander_street_small/meta-llama-L...   \n6           6  finetuning/miti_alexander_street/meta-llama-Ll...   \n7           7   finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6   \n8           8    finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6   \n9           9                     meta-llama/Llama-2-13b-chat-hf   \n\n                                           bertscore  bertscore_f1_mean  \\\n0  {'precision': [0.8521035313606262, 0.889962553...           0.857203   \n1  {'precision': [0.8802219033241272, 0.872217297...           0.846896   \n2  {'precision': [0.8678842782974243, 0.839466869...           0.848894   \n3  {'precision': [0.8176425695419312, 0.863284587...           0.810307   \n4  {'precision': [0.8413432836532593, 0.857688665...           0.846356   \n5  {'precision': [0.9089345932006836, 0.853552818...           0.846750   \n6  {'precision': [0.8477878570556641, 0.875392675...           0.861267   \n7  {'precision': [0.8576045036315918, 0.864270389...           0.862704   \n8  {'precision': [0.8628348112106323, 0.868188798...           0.858311   \n9  {'precision': [0.8004786372184753, 0.829261600...           0.804415   \n\n   bertscore_f1_std  bertscore_precision_mean  bertscore_recall_mean  \\\n0          0.043770                  0.858164               0.857271   \n1          0.029539                  0.853084               0.842088   \n2          0.031134                  0.858908               0.840558   \n3          0.022486                  0.781226               0.842561   \n4          0.028436                  0.853447               0.840669   \n5          0.030293                  0.852244               0.842509   \n6          0.047765                  0.864269               0.859231   \n7          0.050348                  0.865171               0.861135   \n8          0.045633                  0.858091               0.859440   \n9          0.030133                  0.774571               0.837792   \n\n                                                bleu  \\\n0  {'bleu': 0.04714233420857152, 'precisions': [0...   \n1  {'bleu': 0.012781297138857287, 'precisions': [...   \n2  {'bleu': 0.01131199593102045, 'precisions': [0...   \n3  {'bleu': 0.005177354701638891, 'precisions': [...   \n4  {'bleu': 0.01036091804679258, 'precisions': [0...   \n5  {'bleu': 0.012359712161719907, 'precisions': [...   \n6  {'bleu': 0.07003506053910136, 'precisions': [0...   \n7  {'bleu': 0.0607435130248533, 'precisions': [0....   \n8  {'bleu': 0.04286718972283765, 'precisions': [0...   \n9  {'bleu': 0.0052025342864554, 'precisions': [0....   \n\n                                              bleurt  bleurt_f1_mean  ...  \\\n0  {'scores': [-1.5883477926254272, -0.5129691958...       -0.963470  ...   \n1  {'scores': [-1.4992144107818604, -1.6273263692...       -1.145407  ...   \n2  {'scores': [-1.2641234397888184, -1.3700337409...       -1.122640  ...   \n3  {'scores': [-0.9790810942649841, -0.7483015656...       -1.317601  ...   \n4  {'scores': [-1.0119128227233887, -1.6825077533...       -1.172437  ...   \n5  {'scores': [-1.038384199142456, -0.95797485113...       -1.148234  ...   \n6  {'scores': [-1.0559653043746948, -0.9023092389...       -0.898174  ...   \n7  {'scores': [-0.8965473175048828, -0.7514126896...       -0.858924  ...   \n8  {'scores': [-1.4244155883789062, -0.9822391271...       -0.911828  ...   \n9  {'scores': [-0.8908114433288574, -0.5914517641...       -1.331038  ...   \n\n   frugalscore_f1_mean frugalscore_f1_std  \\\n0             0.006566           0.276434   \n1            -0.098164           0.157977   \n2            -0.097693           0.169693   \n3            -0.094603           0.121680   \n4            -0.104471           0.151046   \n5            -0.093074           0.160853   \n6             0.031425           0.310489   \n7             0.050345           0.323301   \n8             0.025398           0.292531   \n9            -0.106791           0.113936   \n\n                             google_bleu                           meteor  \\\n0  {'google_bleu': 0.058391085206639076}   {'meteor': 0.2036675683351478}   \n1   {'google_bleu': 0.03455417966787487}   {'meteor': 0.1255303343638163}   \n2   {'google_bleu': 0.03292305001123111}  {'meteor': 0.11923888191444706}   \n3  {'google_bleu': 0.019129019671542388}   {'meteor': 0.1631574496909516}   \n4   {'google_bleu': 0.03286954239250308}  {'meteor': 0.11967210638136731}   \n5   {'google_bleu': 0.03529539773505573}  {'meteor': 0.12678145049351427}   \n6   {'google_bleu': 0.07078532481310602}  {'meteor': 0.21671404789969428}   \n7   {'google_bleu': 0.06486506624350302}  {'meteor': 0.22925758259801637}   \n8   {'google_bleu': 0.05766905689656642}   {'meteor': 0.2225239151728812}   \n9  {'google_bleu': 0.020428763345130177}  {'meteor': 0.16195078121252887}   \n\n  predicted_utterances_count predicted_words_count_mean  \\\n0                       6652                  29.507817   \n1                       6652                  24.511876   \n2                       6652                  22.558178   \n3                       6652                 173.048256   \n4                       6652                  23.107637   \n5                       6652                  24.351022   \n6                       6652                  24.929946   \n7                       6652                  25.274354   \n8                       6652                  33.305322   \n9                       6652                 166.406194   \n\n   predicted_words_count_std  reference_words_count_mean  \\\n0                  33.912126                   25.904991   \n1                  35.467151                   25.904991   \n2                  33.688205                   25.904991   \n3                  33.089070                   25.904991   \n4                  32.997601                   25.904991   \n5                  33.650652                   25.904991   \n6                  27.325215                   25.904991   \n7                  28.995102                   25.904991   \n8                  36.569563                   25.904991   \n9                  43.370973                   25.904991   \n\n   reference_words_count_std  \\\n0                  29.444664   \n1                  29.444664   \n2                  29.444664   \n3                  29.444664   \n4                  29.444664   \n5                  29.444664   \n6                  29.444664   \n7                  29.444664   \n8                  29.444664   \n9                  29.444664   \n\n                                               rouge  \n0  {'rouge1': 0.2286281584299184, 'rouge2': 0.076...  \n1  {'rouge1': 0.14487632150894864, 'rouge2': 0.02...  \n2  {'rouge1': 0.1385491822036144, 'rouge2': 0.020...  \n3  {'rouge1': 0.10993872775780206, 'rouge2': 0.01...  \n4  {'rouge1': 0.13922652976032834, 'rouge2': 0.02...  \n5  {'rouge1': 0.1467090228221501, 'rouge2': 0.023...  \n6  {'rouge1': 0.249585850179374, 'rouge2': 0.0966...  \n7  {'rouge1': 0.2642435855610533, 'rouge2': 0.105...  \n8  {'rouge1': 0.24632216278547844, 'rouge2': 0.08...  \n9  {'rouge1': 0.1126175778580799, 'rouge2': 0.020...  \n\n[10 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Model</th>\n      <th>bertscore</th>\n      <th>bertscore_f1_mean</th>\n      <th>bertscore_f1_std</th>\n      <th>bertscore_precision_mean</th>\n      <th>bertscore_recall_mean</th>\n      <th>bleu</th>\n      <th>bleurt</th>\n      <th>bleurt_f1_mean</th>\n      <th>...</th>\n      <th>frugalscore_f1_mean</th>\n      <th>frugalscore_f1_std</th>\n      <th>google_bleu</th>\n      <th>meteor</th>\n      <th>predicted_utterances_count</th>\n      <th>predicted_words_count_mean</th>\n      <th>predicted_words_count_std</th>\n      <th>reference_words_count_mean</th>\n      <th>reference_words_count_std</th>\n      <th>rouge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>finetuning/miti_alexander_street/meta-llama-Ll...</td>\n      <td>{'precision': [0.8521035313606262, 0.889962553...</td>\n      <td>0.857203</td>\n      <td>0.043770</td>\n      <td>0.858164</td>\n      <td>0.857271</td>\n      <td>{'bleu': 0.04714233420857152, 'precisions': [0...</td>\n      <td>{'scores': [-1.5883477926254272, -0.5129691958...</td>\n      <td>-0.963470</td>\n      <td>...</td>\n      <td>0.006566</td>\n      <td>0.276434</td>\n      <td>{'google_bleu': 0.058391085206639076}</td>\n      <td>{'meteor': 0.2036675683351478}</td>\n      <td>6652</td>\n      <td>29.507817</td>\n      <td>33.912126</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.2286281584299184, 'rouge2': 0.076...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>finetuning/alexander_street_small/meta-llama-L...</td>\n      <td>{'precision': [0.8802219033241272, 0.872217297...</td>\n      <td>0.846896</td>\n      <td>0.029539</td>\n      <td>0.853084</td>\n      <td>0.842088</td>\n      <td>{'bleu': 0.012781297138857287, 'precisions': [...</td>\n      <td>{'scores': [-1.4992144107818604, -1.6273263692...</td>\n      <td>-1.145407</td>\n      <td>...</td>\n      <td>-0.098164</td>\n      <td>0.157977</td>\n      <td>{'google_bleu': 0.03455417966787487}</td>\n      <td>{'meteor': 0.1255303343638163}</td>\n      <td>6652</td>\n      <td>24.511876</td>\n      <td>35.467151</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.14487632150894864, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>finetuning/alexander_street_large/meta-llama-L...</td>\n      <td>{'precision': [0.8678842782974243, 0.839466869...</td>\n      <td>0.848894</td>\n      <td>0.031134</td>\n      <td>0.858908</td>\n      <td>0.840558</td>\n      <td>{'bleu': 0.01131199593102045, 'precisions': [0...</td>\n      <td>{'scores': [-1.2641234397888184, -1.3700337409...</td>\n      <td>-1.122640</td>\n      <td>...</td>\n      <td>-0.097693</td>\n      <td>0.169693</td>\n      <td>{'google_bleu': 0.03292305001123111}</td>\n      <td>{'meteor': 0.11923888191444706}</td>\n      <td>6652</td>\n      <td>22.558178</td>\n      <td>33.688205</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1385491822036144, 'rouge2': 0.020...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>meta-llama/Llama-2-7b-chat-hf</td>\n      <td>{'precision': [0.8176425695419312, 0.863284587...</td>\n      <td>0.810307</td>\n      <td>0.022486</td>\n      <td>0.781226</td>\n      <td>0.842561</td>\n      <td>{'bleu': 0.005177354701638891, 'precisions': [...</td>\n      <td>{'scores': [-0.9790810942649841, -0.7483015656...</td>\n      <td>-1.317601</td>\n      <td>...</td>\n      <td>-0.094603</td>\n      <td>0.121680</td>\n      <td>{'google_bleu': 0.019129019671542388}</td>\n      <td>{'meteor': 0.1631574496909516}</td>\n      <td>6652</td>\n      <td>173.048256</td>\n      <td>33.089070</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.10993872775780206, 'rouge2': 0.01...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>finetuning/alexander_street_large/meta-llama-L...</td>\n      <td>{'precision': [0.8413432836532593, 0.857688665...</td>\n      <td>0.846356</td>\n      <td>0.028436</td>\n      <td>0.853447</td>\n      <td>0.840669</td>\n      <td>{'bleu': 0.01036091804679258, 'precisions': [0...</td>\n      <td>{'scores': [-1.0119128227233887, -1.6825077533...</td>\n      <td>-1.172437</td>\n      <td>...</td>\n      <td>-0.104471</td>\n      <td>0.151046</td>\n      <td>{'google_bleu': 0.03286954239250308}</td>\n      <td>{'meteor': 0.11967210638136731}</td>\n      <td>6652</td>\n      <td>23.107637</td>\n      <td>32.997601</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.13922652976032834, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>finetuning/alexander_street_small/meta-llama-L...</td>\n      <td>{'precision': [0.9089345932006836, 0.853552818...</td>\n      <td>0.846750</td>\n      <td>0.030293</td>\n      <td>0.852244</td>\n      <td>0.842509</td>\n      <td>{'bleu': 0.012359712161719907, 'precisions': [...</td>\n      <td>{'scores': [-1.038384199142456, -0.95797485113...</td>\n      <td>-1.148234</td>\n      <td>...</td>\n      <td>-0.093074</td>\n      <td>0.160853</td>\n      <td>{'google_bleu': 0.03529539773505573}</td>\n      <td>{'meteor': 0.12678145049351427}</td>\n      <td>6652</td>\n      <td>24.351022</td>\n      <td>33.650652</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1467090228221501, 'rouge2': 0.023...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>finetuning/miti_alexander_street/meta-llama-Ll...</td>\n      <td>{'precision': [0.8477878570556641, 0.875392675...</td>\n      <td>0.861267</td>\n      <td>0.047765</td>\n      <td>0.864269</td>\n      <td>0.859231</td>\n      <td>{'bleu': 0.07003506053910136, 'precisions': [0...</td>\n      <td>{'scores': [-1.0559653043746948, -0.9023092389...</td>\n      <td>-0.898174</td>\n      <td>...</td>\n      <td>0.031425</td>\n      <td>0.310489</td>\n      <td>{'google_bleu': 0.07078532481310602}</td>\n      <td>{'meteor': 0.21671404789969428}</td>\n      <td>6652</td>\n      <td>24.929946</td>\n      <td>27.325215</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.249585850179374, 'rouge2': 0.0966...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6</td>\n      <td>{'precision': [0.8576045036315918, 0.864270389...</td>\n      <td>0.862704</td>\n      <td>0.050348</td>\n      <td>0.865171</td>\n      <td>0.861135</td>\n      <td>{'bleu': 0.0607435130248533, 'precisions': [0....</td>\n      <td>{'scores': [-0.8965473175048828, -0.7514126896...</td>\n      <td>-0.858924</td>\n      <td>...</td>\n      <td>0.050345</td>\n      <td>0.323301</td>\n      <td>{'google_bleu': 0.06486506624350302}</td>\n      <td>{'meteor': 0.22925758259801637}</td>\n      <td>6652</td>\n      <td>25.274354</td>\n      <td>28.995102</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.2642435855610533, 'rouge2': 0.105...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6</td>\n      <td>{'precision': [0.8628348112106323, 0.868188798...</td>\n      <td>0.858311</td>\n      <td>0.045633</td>\n      <td>0.858091</td>\n      <td>0.859440</td>\n      <td>{'bleu': 0.04286718972283765, 'precisions': [0...</td>\n      <td>{'scores': [-1.4244155883789062, -0.9822391271...</td>\n      <td>-0.911828</td>\n      <td>...</td>\n      <td>0.025398</td>\n      <td>0.292531</td>\n      <td>{'google_bleu': 0.05766905689656642}</td>\n      <td>{'meteor': 0.2225239151728812}</td>\n      <td>6652</td>\n      <td>33.305322</td>\n      <td>36.569563</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.24632216278547844, 'rouge2': 0.08...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>meta-llama/Llama-2-13b-chat-hf</td>\n      <td>{'precision': [0.8004786372184753, 0.829261600...</td>\n      <td>0.804415</td>\n      <td>0.030133</td>\n      <td>0.774571</td>\n      <td>0.837792</td>\n      <td>{'bleu': 0.0052025342864554, 'precisions': [0....</td>\n      <td>{'scores': [-0.8908114433288574, -0.5914517641...</td>\n      <td>-1.331038</td>\n      <td>...</td>\n      <td>-0.106791</td>\n      <td>0.113936</td>\n      <td>{'google_bleu': 0.020428763345130177}</td>\n      <td>{'meteor': 0.16195078121252887}</td>\n      <td>6652</td>\n      <td>166.406194</td>\n      <td>43.370973</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1126175778580799, 'rouge2': 0.020...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_existing_evals"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:05:13.926446900Z",
     "start_time": "2024-02-19T11:05:13.895441900Z"
    }
   },
   "id": "d47210f13f74b2d4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('O')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_existing_evals['bertscore'].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:33:30.831430500Z",
     "start_time": "2024-02-19T11:33:30.810430Z"
    }
   },
   "id": "683f03af62fba353",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:27:48.611224300Z",
     "start_time": "2024-02-19T11:27:48.485713100Z"
    }
   },
   "id": "3ea55a08a2e459cf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U394318'), dtype('<U394318')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUFuncTypeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43m_df_existing_evals\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbertscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1104\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1154\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1155\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1156\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1163\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1164\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn [23], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m _df_existing_evals[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _methods\u001B[38;5;241m.\u001B[39m_mean(a, axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   3505\u001B[0m                       out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\numpy\\core\\_methods.py:118\u001B[0m, in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    115\u001B[0m         dtype \u001B[38;5;241m=\u001B[39m mu\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    116\u001B[0m         is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 118\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, mu\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _no_nep50_warning():\n",
      "\u001B[1;31mUFuncTypeError\u001B[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U394318'), dtype('<U394318')) -> None"
     ]
    }
   ],
   "source": [
    "_df_existing_evals['bertscore'].apply(lambda x: np.mean(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:29:34.334449400Z",
     "start_time": "2024-02-19T11:29:34.211621900Z"
    }
   },
   "id": "592ee660c00fd608",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from statsmodels.sandbox.stats.multicomp import TukeyHSDResults\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "def calculate_anova(scores: pd.DataFrame, verbose: bool = False) -> TukeyHSDResults:\n",
    "    models_name = scores['Model'].unique().tolist()\n",
    "\n",
    "    func = lambda model_name: scores[scores['Model'] == model_name]['bertscore']['precision']\n",
    "\n",
    "    # Perform One-Way ANOVA\n",
    "    anova_result = f_oneway(*[func(model_name=model_name) for model_name in models_name])\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ANOVA Result:\\n{anova_result}\\n\")\n",
    "\n",
    "    # If ANOVA is significant, perform post hoc test\n",
    "    if anova_result.pvalue < 0.05:\n",
    "        # Prepare data for Tukey's HSD test\n",
    "        tukey_data = scores[['Model', 'Mean Value']]\n",
    "        tukey_test = pairwise_tukeyhsd(endog=tukey_data['Mean Value'], groups=tukey_data['Model'], alpha=0.05)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Tukey's HSD Test Result:\")\n",
    "            print(tukey_test)\n",
    "\n",
    "        return tukey_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:27:00.522588300Z",
     "start_time": "2024-02-19T11:27:00.491590400Z"
    }
   },
   "id": "ca8f50b4618371ea",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\_libs\\index.pyx:146\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\index_class_helper.pxi:49\u001B[0m, in \u001B[0;36mpandas._libs.index.Int64Engine._check_type\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'precision'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcalculate_anova\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_df_existing_evals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [9], line 12\u001B[0m, in \u001B[0;36mcalculate_anova\u001B[1;34m(scores, verbose)\u001B[0m\n\u001B[0;32m      9\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m model_name: scores[scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m model_name][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Perform One-Way ANOVA\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m anova_result \u001B[38;5;241m=\u001B[39m f_oneway(\u001B[38;5;241m*\u001B[39m[func(model_name\u001B[38;5;241m=\u001B[39mmodel_name) \u001B[38;5;28;01mfor\u001B[39;00m model_name \u001B[38;5;129;01min\u001B[39;00m models_name])\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mANOVA Result:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00manova_result\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn [9], line 12\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      9\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m model_name: scores[scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m model_name][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Perform One-Way ANOVA\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m anova_result \u001B[38;5;241m=\u001B[39m f_oneway(\u001B[38;5;241m*\u001B[39m[\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m model_name \u001B[38;5;129;01min\u001B[39;00m models_name])\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mANOVA Result:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00manova_result\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn [9], line 9\u001B[0m, in \u001B[0;36mcalculate_anova.<locals>.<lambda>\u001B[1;34m(model_name)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_anova\u001B[39m(scores: pd\u001B[38;5;241m.\u001B[39mDataFrame, verbose: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m TukeyHSDResults:\n\u001B[0;32m      7\u001B[0m     models_name \u001B[38;5;241m=\u001B[39m scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m----> 9\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m model_name: \u001B[43mscores\u001B[49m\u001B[43m[\u001B[49m\u001B[43mscores\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mModel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbertscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# Perform One-Way ANOVA\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     anova_result \u001B[38;5;241m=\u001B[39m f_oneway(\u001B[38;5;241m*\u001B[39m[func(model_name\u001B[38;5;241m=\u001B[39mmodel_name) \u001B[38;5;28;01mfor\u001B[39;00m model_name \u001B[38;5;129;01min\u001B[39;00m models_name])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\series.py:981\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    978\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m--> 981\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    986\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\series.py:1089\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1089\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_get_values_for_loc(\u001B[38;5;28mself\u001B[39m, loc, label)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'precision'"
     ]
    }
   ],
   "source": [
    "calculate_anova(_df_existing_evals, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:27:07.574038Z",
     "start_time": "2024-02-19T11:27:06.732742600Z"
    }
   },
   "id": "666ceac457bbd2f7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_df_existing_evals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43m_df_existing_evals\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name '_df_existing_evals' is not defined"
     ]
    }
   ],
   "source": [
    "_df_existing_evals"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:05:05.418194100Z",
     "start_time": "2024-02-19T11:05:05.156670500Z"
    }
   },
   "id": "bf869f18e1f12461",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_df = None\n",
    "for _doc in TABLE_MITI.find({'llama2': {'$exists': True}}):\n",
    "    _true_response = _doc['prompt']['true_response']\n",
    "    _llama2 = _doc['llama2']\n",
    "    _llama2['true_response'] = _true_response\n",
    "\n",
    "    _df_tmp = pd.DataFrame.from_dict({k: [v] for k, v in _llama2.items()})\n",
    "    if _df is None:\n",
    "        _df = _df_tmp\n",
    "    else:\n",
    "        _df = pd.concat([_df, _df_tmp], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:20.419225100Z",
     "start_time": "2024-02-19T10:24:15.362517600Z"
    }
   },
   "id": "93215a6224171703",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     finetuning/miti_alexander_street/meta-llama-Llama-2-7b-chat-hf-6  \\\n0        okay, what kind of workouts do you usually do?                 \n1     Okay. Well, you seem like you're feeling a lit...                 \n2     Yeah, so it sounds like you're saying that you...                 \n3                                 got really exhausted.                 \n4     You said that your family is kind of concerned...                 \n...                                                 ...                 \n6647                                               yeah                 \n6648  well it's important that you've identified tha...                 \n6649  well thanks for your willingness to talk about...                 \n6650                 uh-huh okay and then what happened                 \n6651  not that big of a deal well I want to show you...                 \n\n     finetuning/alexander_street_small/meta-llama-Llama-2-7b-chat-hf-6  \\\n0     So, you're going to school and you're working ...                  \n1                                           Sure, sure.                  \n2     But, you know, they probably care about you, a...                  \n3                                               Uh-huh.                  \n4     But I guess my question is how are you feeling...                  \n...                                                 ...                  \n6647  oh yeah I mean I was on the phone with someone...                  \n6648  okay and the idea is to not stop smoking right...                  \n6649  I can tell you that I know people who've used ...                  \n6650  You didn't take the time to think about the co...                  \n6651  really well let me tell you something it is a ...                  \n\n     finetuning/alexander_street_large/meta-llama-Llama-2-7b-chat-hf-6  \\\n0     So what do you do when you're not going to sch...                  \n1                                           I guess so.                  \n2                           How much time are you home?                  \n3     Yeah, well, I wonder if the, the symptoms you'...                  \n4     Yeah, and you're a little concerned about your...                  \n...                                                 ...                  \n6647                                              okay.                  \n6648        yeah I'd recommend you know look into that.                  \n6649  okay and I'm going to put you on hold for a se...                  \n6650                                              okay.                  \n6651  you have a lot of good things going for you bu...                  \n\n                          meta-llama/Llama-2-7b-chat-hf  \\\n0     okay, got it. So, can you tell me a little bit...   \n1     Okay, I see. So, it sounds like you're feeling...   \n2     It seems like you're feeling kind of frustrate...   \n3     I see, so it sounds like you were experiencing...   \n4     Okay, and you mentioned that your parents are ...   \n...                                                 ...   \n6647  yah right yeah definitely yeah yeah definitely...   \n6648  yeah yeah I see what you mean I think that the...   \n6649  great okay so let's talk about some other opti...   \n6650  okay so let me get this straight you got into ...   \n6651  you say that now but how do you know what the ...   \n\n                         meta-llama/Llama-2-13b-chat-hf  \\\n0     I see, yeah okay and do you do you have any th...   \n1     I mean, it sounds like it sounds like you're f...   \n2     So, it sounds like you're feeling really confl...   \n3     Okay, it sounds like it's not just been that y...   \n4     Can you tell me more about that? What do you m...   \n...                                                 ...   \n6647  yeah\\n user\\nI mean my my my healthcare provid...   \n6648  yeah i got it so you know you've been having d...   \n6649  great well let me tell you I know that there i...   \n6650  who did you go to the science fair with?\\n use...   \n6651  whatever it was, it was a bad idea it was stup...   \n\n     finetuning/alexander_street_large/meta-llama-Llama-2-13b-chat-hf-6  \\\n0     And are you planning on going back to school a...                   \n1     They love to have you home with them all the t...                   \n2     Right. I mean, what's a little overly concerne...                   \n3     Okay, so, so that's what your parents were res...                   \n4     Yeah, what do you think you were experiencing,...                   \n...                                                 ...                   \n6647  yeah but you're not ready to commit to that I ...                   \n6648  yeah I I'm really glad you asked because I thi...                   \n6649  and it's good that your on board with that pro...                   \n6650  But it was a guy that you had never driven wit...                   \n6651                                              it is                   \n\n     finetuning/alexander_street_small/meta-llama-Llama-2-13b-chat-hf-6  \\\n0           Okay, so you're taking a break from school?                   \n1     Well, they love you and they want to help you,...                   \n2     Yeah, I mean, well, I'm sure it's just you kno...                   \n3     Did you feel tired or you were feeling like ti...                   \n4                                                Right.                   \n...                                                 ...                   \n6647  yeah sure yeah it's something that if you want...                   \n6648  yeah so well let's I mean one of the things th...                   \n6649  good because that's the whole point of me bein...                   \n6650                   what's the science fair project?                   \n6651                      it is a huge deal you can die                   \n\n     finetuning/miti_alexander_street/meta-llama-Llama-2-13b-chat-hf-6  \\\n0     You work out, that's good! I'm curious because...                  \n1     yeah, so, it sounds like you are you're really...                  \n2                                     Overly concerned?                  \n3     so, it just sound like you were kind of draggi...                  \n4     I do know that your parents are definitely con...                  \n...                                                 ...                  \n6647                                         absolutely                  \n6648  yeah well you've taken the first step Will by ...                  \n6649  absolutely okay so I really want to thank you ...                  \n6650   so you saw no harm in smoking marijuana that day                  \n6651  it wasn't a big deal to you because you didn't...                  \n\n       finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6  \\\n0     So you're a typical college student. So you sa...   \n1     You're feeling torn almost like you're pulling...   \n2     Well, it seems like your parents have a lot of...   \n3                           So, you're really fatigued.   \n4     So you don't have any idea why you get the sym...   \n...                                                 ...   \n6647                                               yeah   \n6648  yeah I guess what I'm hearing you say is that ...   \n6649  ok good so there are some other products that ...   \n6650  so it was you know sometimes it's kind of fun ...   \n6651  not that big of a deal you could have died he ...   \n\n        finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6  \\\n0     alright, well you mentioned that you like to w...   \n1     Well, it sounds like you are a motivated perso...   \n2     Okay, so it seems like your family is really w...   \n3     and you don't feel like that's related to stress.   \n4     So, it seems like you're really confused about...   \n...                                                 ...   \n6647  and so you could see yourself doing something ...   \n6648  so you've heard mixed messages that sometimes ...   \n6649  so that's great I mean I don't know if you hav...   \n6650  um okay okay so um what else can you tell me a...   \n6651  it may have been for you but let me tell you w...   \n\n                                          true_response  \n0     Well, they sounds like you're really, really h...  \n1     So, it seems like your kind of conflicted abou...  \n2     Can you tell a little bit more about what you ...  \n3     so, it sounds like you're really confused abou...  \n4     I know that you really discuss that working ou...  \n...                                                 ...  \n6647                                         absolutely  \n6648  well you've taken an important step Will one o...  \n6649                                              great  \n6650  science fair project or not don't you know wha...  \n6651  it's a big deal you can't drink either you're ...  \n\n[6652 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>finetuning/miti_alexander_street/meta-llama-Llama-2-7b-chat-hf-6</th>\n      <th>finetuning/alexander_street_small/meta-llama-Llama-2-7b-chat-hf-6</th>\n      <th>finetuning/alexander_street_large/meta-llama-Llama-2-7b-chat-hf-6</th>\n      <th>meta-llama/Llama-2-7b-chat-hf</th>\n      <th>meta-llama/Llama-2-13b-chat-hf</th>\n      <th>finetuning/alexander_street_large/meta-llama-Llama-2-13b-chat-hf-6</th>\n      <th>finetuning/alexander_street_small/meta-llama-Llama-2-13b-chat-hf-6</th>\n      <th>finetuning/miti_alexander_street/meta-llama-Llama-2-13b-chat-hf-6</th>\n      <th>finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6</th>\n      <th>finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6</th>\n      <th>true_response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>okay, what kind of workouts do you usually do?</td>\n      <td>So, you're going to school and you're working ...</td>\n      <td>So what do you do when you're not going to sch...</td>\n      <td>okay, got it. So, can you tell me a little bit...</td>\n      <td>I see, yeah okay and do you do you have any th...</td>\n      <td>And are you planning on going back to school a...</td>\n      <td>Okay, so you're taking a break from school?</td>\n      <td>You work out, that's good! I'm curious because...</td>\n      <td>So you're a typical college student. So you sa...</td>\n      <td>alright, well you mentioned that you like to w...</td>\n      <td>Well, they sounds like you're really, really h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Okay. Well, you seem like you're feeling a lit...</td>\n      <td>Sure, sure.</td>\n      <td>I guess so.</td>\n      <td>Okay, I see. So, it sounds like you're feeling...</td>\n      <td>I mean, it sounds like it sounds like you're f...</td>\n      <td>They love to have you home with them all the t...</td>\n      <td>Well, they love you and they want to help you,...</td>\n      <td>yeah, so, it sounds like you are you're really...</td>\n      <td>You're feeling torn almost like you're pulling...</td>\n      <td>Well, it sounds like you are a motivated perso...</td>\n      <td>So, it seems like your kind of conflicted abou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yeah, so it sounds like you're saying that you...</td>\n      <td>But, you know, they probably care about you, a...</td>\n      <td>How much time are you home?</td>\n      <td>It seems like you're feeling kind of frustrate...</td>\n      <td>So, it sounds like you're feeling really confl...</td>\n      <td>Right. I mean, what's a little overly concerne...</td>\n      <td>Yeah, I mean, well, I'm sure it's just you kno...</td>\n      <td>Overly concerned?</td>\n      <td>Well, it seems like your parents have a lot of...</td>\n      <td>Okay, so it seems like your family is really w...</td>\n      <td>Can you tell a little bit more about what you ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>got really exhausted.</td>\n      <td>Uh-huh.</td>\n      <td>Yeah, well, I wonder if the, the symptoms you'...</td>\n      <td>I see, so it sounds like you were experiencing...</td>\n      <td>Okay, it sounds like it's not just been that y...</td>\n      <td>Okay, so, so that's what your parents were res...</td>\n      <td>Did you feel tired or you were feeling like ti...</td>\n      <td>so, it just sound like you were kind of draggi...</td>\n      <td>So, you're really fatigued.</td>\n      <td>and you don't feel like that's related to stress.</td>\n      <td>so, it sounds like you're really confused abou...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You said that your family is kind of concerned...</td>\n      <td>But I guess my question is how are you feeling...</td>\n      <td>Yeah, and you're a little concerned about your...</td>\n      <td>Okay, and you mentioned that your parents are ...</td>\n      <td>Can you tell me more about that? What do you m...</td>\n      <td>Yeah, what do you think you were experiencing,...</td>\n      <td>Right.</td>\n      <td>I do know that your parents are definitely con...</td>\n      <td>So you don't have any idea why you get the sym...</td>\n      <td>So, it seems like you're really confused about...</td>\n      <td>I know that you really discuss that working ou...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6647</th>\n      <td>yeah</td>\n      <td>oh yeah I mean I was on the phone with someone...</td>\n      <td>okay.</td>\n      <td>yah right yeah definitely yeah yeah definitely...</td>\n      <td>yeah\\n user\\nI mean my my my healthcare provid...</td>\n      <td>yeah but you're not ready to commit to that I ...</td>\n      <td>yeah sure yeah it's something that if you want...</td>\n      <td>absolutely</td>\n      <td>yeah</td>\n      <td>and so you could see yourself doing something ...</td>\n      <td>absolutely</td>\n    </tr>\n    <tr>\n      <th>6648</th>\n      <td>well it's important that you've identified tha...</td>\n      <td>okay and the idea is to not stop smoking right...</td>\n      <td>yeah I'd recommend you know look into that.</td>\n      <td>yeah yeah I see what you mean I think that the...</td>\n      <td>yeah i got it so you know you've been having d...</td>\n      <td>yeah I I'm really glad you asked because I thi...</td>\n      <td>yeah so well let's I mean one of the things th...</td>\n      <td>yeah well you've taken the first step Will by ...</td>\n      <td>yeah I guess what I'm hearing you say is that ...</td>\n      <td>so you've heard mixed messages that sometimes ...</td>\n      <td>well you've taken an important step Will one o...</td>\n    </tr>\n    <tr>\n      <th>6649</th>\n      <td>well thanks for your willingness to talk about...</td>\n      <td>I can tell you that I know people who've used ...</td>\n      <td>okay and I'm going to put you on hold for a se...</td>\n      <td>great okay so let's talk about some other opti...</td>\n      <td>great well let me tell you I know that there i...</td>\n      <td>and it's good that your on board with that pro...</td>\n      <td>good because that's the whole point of me bein...</td>\n      <td>absolutely okay so I really want to thank you ...</td>\n      <td>ok good so there are some other products that ...</td>\n      <td>so that's great I mean I don't know if you hav...</td>\n      <td>great</td>\n    </tr>\n    <tr>\n      <th>6650</th>\n      <td>uh-huh okay and then what happened</td>\n      <td>You didn't take the time to think about the co...</td>\n      <td>okay.</td>\n      <td>okay so let me get this straight you got into ...</td>\n      <td>who did you go to the science fair with?\\n use...</td>\n      <td>But it was a guy that you had never driven wit...</td>\n      <td>what's the science fair project?</td>\n      <td>so you saw no harm in smoking marijuana that day</td>\n      <td>so it was you know sometimes it's kind of fun ...</td>\n      <td>um okay okay so um what else can you tell me a...</td>\n      <td>science fair project or not don't you know wha...</td>\n    </tr>\n    <tr>\n      <th>6651</th>\n      <td>not that big of a deal well I want to show you...</td>\n      <td>really well let me tell you something it is a ...</td>\n      <td>you have a lot of good things going for you bu...</td>\n      <td>you say that now but how do you know what the ...</td>\n      <td>whatever it was, it was a bad idea it was stup...</td>\n      <td>it is</td>\n      <td>it is a huge deal you can die</td>\n      <td>it wasn't a big deal to you because you didn't...</td>\n      <td>not that big of a deal you could have died he ...</td>\n      <td>it may have been for you but let me tell you w...</td>\n      <td>it's a big deal you can't drink either you're ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6652 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:20.447123300Z",
     "start_time": "2024-02-19T10:24:20.420458400Z"
    }
   },
   "id": "1955ad8a6d5c7055",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\stav3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\stav3\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\1dfb731fe2846298242021b3971e53cd2b22233cb0c4fdd87721b208630c396f\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "WARNING:tensorflow:From C:\\Users\\stav3\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "_bleu = evaluate.load(\"bleu\")\n",
    "_rouge = evaluate.load(\"rouge\")\n",
    "_meteor = evaluate.load(\"meteor\")\n",
    "_bertscore = evaluate.load(\"bertscore\", device='cuda:0')\n",
    "_frugalscore = evaluate.load(\"frugalscore\", \"moussaKam/frugalscore_medium_bert-base_mover-score\")\n",
    "_google_bleu = evaluate.load(\"google_bleu\")\n",
    "_bleurt = evaluate.load(\"bleurt\", module_type=\"metric\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:34.892273400Z",
     "start_time": "2024-02-19T10:24:20.436613500Z"
    }
   },
   "id": "722914b7c919d467",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_eval = defaultdict(defaultdict)\n",
    "\n",
    "for _k in _df.columns:\n",
    "    if _k == 'true_response':\n",
    "        continue\n",
    "    if _df_existing_evals['Model'].isin([_k]).any():\n",
    "        continue\n",
    "\n",
    "    print(f'Processing {_k} ...')\n",
    "\n",
    "    _predictions = _df[_k].tolist()\n",
    "    _references = _df['true_response'].tolist()\n",
    "    _eval[_k]['predicted_utterances_count'] = len(_df)\n",
    "    _eval[_k]['predicted_words_count_mean'] = np.mean(_df[_k].apply(lambda x: len(x.split())))\n",
    "    _eval[_k]['predicted_words_count_std'] = np.std(_df[_k].apply(lambda x: len(x.split())))\n",
    "    _eval[_k]['reference_words_count_mean'] = np.mean(_df['true_response'].apply(lambda x: len(x.split())))\n",
    "    _eval[_k]['reference_words_count_std'] = np.std(_df['true_response'].apply(lambda x: len(x.split())))\n",
    "\n",
    "    print('Calculating BLEU...')\n",
    "    _eval[_k]['bleu'] = _bleu.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references\n",
    "    )\n",
    "\n",
    "    print('Calculating ROUGE...')\n",
    "    _eval[_k]['rouge'] = _rouge.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references\n",
    "    )\n",
    "\n",
    "    print('Calculating METEOR...')\n",
    "    _eval[_k]['meteor'] = _meteor.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references\n",
    "    )\n",
    "\n",
    "    print('Calculating BERTScore...')\n",
    "    _eval[_k]['bertscore'] = _bertscore.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references,\n",
    "        lang=\"en\"\n",
    "    )\n",
    "\n",
    "    print('Calculating FrugalScore...')\n",
    "    _eval[_k]['frugalscore'] = _frugalscore.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references,\n",
    "        batch_size=16,\n",
    "        max_length=64,\n",
    "        device=\"gpu\"\n",
    "    )\n",
    "\n",
    "    print('Calculating Google BLEU...')\n",
    "    _eval[_k]['google_bleu'] = _google_bleu.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references\n",
    "    )\n",
    "\n",
    "    print('Calculating BLEURT...')\n",
    "    _eval[_k]['bleurt'] = _bleurt.compute(\n",
    "        predictions=_predictions,\n",
    "        references=_references\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:34.902780400Z",
     "start_time": "2024-02-19T10:24:34.888213200Z"
    }
   },
   "id": "1577662f36253f16",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(collections.defaultdict, {})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:34.927327500Z",
     "start_time": "2024-02-19T10:24:34.903781100Z"
    }
   },
   "id": "281825dd821e1880",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_result = pd.DataFrame.from_dict(_eval)\n",
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:34.939502500Z",
     "start_time": "2024-02-19T10:24:34.919288100Z"
    }
   },
   "id": "d47d3dd1dcb9354d",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_result = _df_result.T\n",
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:34.964197300Z",
     "start_time": "2024-02-19T10:24:34.934998100Z"
    }
   },
   "id": "a0b3e3007f49d7a5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bertscore'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'bertscore'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _k \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m----> 2\u001B[0m     _df_result[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_k\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_mean\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43m_df_result\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbertscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m _x: np\u001B[38;5;241m.\u001B[39mmean(_x[_k]))\n\u001B[0;32m      4\u001B[0m _df_result[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_k\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_std\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m _df_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbertscore\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m _x: np\u001B[38;5;241m.\u001B[39mstd(_x[_k]))\n\u001B[0;32m      6\u001B[0m _df_result[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrugalscore_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_k\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_mean\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m _df_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrugalscore\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m _x: np\u001B[38;5;241m.\u001B[39mmean(_x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscores\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis_GPTJ_Flask\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'bertscore'"
     ]
    }
   ],
   "source": [
    "for _k in ['precision', 'recall', 'f1']:\n",
    "    _df_result[f'bertscore_{_k}_mean'] = _df_result['bertscore'].apply(lambda _x: np.mean(_x[_k]))\n",
    "\n",
    "_df_result[f'bertscore_{_k}_std'] = _df_result['bertscore'].apply(lambda _x: np.std(_x[_k]))\n",
    "\n",
    "_df_result[f'frugalscore_{_k}_mean'] = _df_result['frugalscore'].apply(lambda _x: np.mean(_x['scores']))\n",
    "_df_result[f'frugalscore_{_k}_std'] = _df_result['frugalscore'].apply(lambda _x: np.std(_x['scores']))\n",
    "\n",
    "_df_result[f'bleurt_{_k}_mean'] = _df_result['bleurt'].apply(lambda _x: np.mean(_x['scores']))\n",
    "_df_result[f'bleurt_{_k}_std'] = _df_result['bleurt'].apply(lambda _x: np.std(_x['scores']))\n",
    "\n",
    "_sorted_columns = sorted(_df_result.columns.tolist())\n",
    "_df_result['Model'] = _df_result.index\n",
    "_df_result = _df_result[['Model'] + _sorted_columns]\n",
    "_df_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:24:36.263165600Z",
     "start_time": "2024-02-19T10:24:34.953015900Z"
    }
   },
   "id": "bfca9ae614ac8032",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_combine_df = pd.concat([_df_existing_evals, _df_result], axis=0).reset_index(drop=True)\n",
    "_combine_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T10:24:36.264168900Z"
    }
   },
   "id": "4c8ff4e4529007b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_combine_df.to_csv('llama2_eval.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T17:43:59.548154600Z",
     "start_time": "2024-02-13T17:43:59.462226300Z"
    }
   },
   "id": "5b28ce290a0cfdfa",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_df_no_arrays = _combine_df.drop(columns=['bleu', 'bertscore', 'frugalscore', 'bleurt', ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T17:44:00.035183300Z",
     "start_time": "2024-02-13T17:44:00.013655500Z"
    }
   },
   "id": "47e18c30201e3739",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Model  bertscore_f1_mean  \\\n0  finetuning/miti_alexander_street/meta-llama-Ll...           0.857203   \n1  finetuning/alexander_street_small/meta-llama-L...           0.846896   \n2  finetuning/alexander_street_large/meta-llama-L...           0.848894   \n3                      meta-llama/Llama-2-7b-chat-hf           0.810307   \n4  finetuning/alexander_street_large/meta-llama-L...           0.846356   \n5  finetuning/alexander_street_small/meta-llama-L...           0.846750   \n6  finetuning/miti_alexander_street/meta-llama-Ll...           0.861267   \n7   finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6           0.862704   \n8    finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6           0.858311   \n9                     meta-llama/Llama-2-13b-chat-hf           0.804415   \n\n   bertscore_f1_std  bertscore_precision_mean  bertscore_recall_mean  \\\n0          0.043770                  0.858164               0.857271   \n1          0.029539                  0.853084               0.842088   \n2          0.031134                  0.858908               0.840558   \n3          0.022486                  0.781226               0.842561   \n4          0.028436                  0.853447               0.840669   \n5          0.030293                  0.852244               0.842509   \n6          0.047765                  0.864269               0.859231   \n7          0.050348                  0.865171               0.861135   \n8          0.045633                  0.858091               0.859440   \n9          0.030133                  0.774571               0.837792   \n\n   bleurt_f1_mean  bleurt_f1_std  frugalscore_f1_mean  frugalscore_f1_std  \\\n0       -0.963470       0.640698             0.006566            0.276434   \n1       -1.145407       0.485106            -0.098164            0.157977   \n2       -1.122640       0.513625            -0.097693            0.169693   \n3       -1.317601       0.441668            -0.094603            0.121680   \n4       -1.172437       0.484274            -0.104471            0.151046   \n5       -1.148234       0.494833            -0.093074            0.160853   \n6       -0.898174       0.691943             0.031425            0.310489   \n7       -0.858924       0.718365             0.050345            0.323301   \n8       -0.911828       0.670952             0.025398            0.292531   \n9       -1.331038       0.416551            -0.106791            0.113936   \n\n                             google_bleu                           meteor  \\\n0  {'google_bleu': 0.058391085206639076}   {'meteor': 0.2036675683351478}   \n1   {'google_bleu': 0.03455417966787487}   {'meteor': 0.1255303343638163}   \n2   {'google_bleu': 0.03292305001123111}  {'meteor': 0.11923888191444706}   \n3  {'google_bleu': 0.019129019671542388}   {'meteor': 0.1631574496909516}   \n4   {'google_bleu': 0.03286954239250308}  {'meteor': 0.11967210638136731}   \n5   {'google_bleu': 0.03529539773505573}  {'meteor': 0.12678145049351427}   \n6   {'google_bleu': 0.07078532481310602}  {'meteor': 0.21671404789969428}   \n7   {'google_bleu': 0.06486506624350302}  {'meteor': 0.22925758259801637}   \n8   {'google_bleu': 0.05766905689656642}   {'meteor': 0.2225239151728812}   \n9  {'google_bleu': 0.020428763345130177}  {'meteor': 0.16195078121252887}   \n\n  predicted_utterances_count predicted_words_count_mean  \\\n0                       6652                  29.507817   \n1                       6652                  24.511876   \n2                       6652                  22.558178   \n3                       6652                 173.048256   \n4                       6652                  23.107637   \n5                       6652                  24.351022   \n6                       6652                  24.929946   \n7                       6652                  25.274354   \n8                       6652                  33.305322   \n9                       6652                 166.406194   \n\n  predicted_words_count_std reference_words_count_mean  \\\n0                 33.912126                  25.904991   \n1                 35.467151                  25.904991   \n2                 33.688205                  25.904991   \n3                  33.08907                  25.904991   \n4                 32.997601                  25.904991   \n5                 33.650652                  25.904991   \n6                 27.325215                  25.904991   \n7                 28.995102                  25.904991   \n8                 36.569563                  25.904991   \n9                 43.370973                  25.904991   \n\n  reference_words_count_std                                              rouge  \n0                 29.444664  {'rouge1': 0.2286281584299184, 'rouge2': 0.076...  \n1                 29.444664  {'rouge1': 0.14487632150894864, 'rouge2': 0.02...  \n2                 29.444664  {'rouge1': 0.1385491822036144, 'rouge2': 0.020...  \n3                 29.444664  {'rouge1': 0.10993872775780206, 'rouge2': 0.01...  \n4                 29.444664  {'rouge1': 0.13922652976032834, 'rouge2': 0.02...  \n5                 29.444664  {'rouge1': 0.1467090228221501, 'rouge2': 0.023...  \n6                 29.444664  {'rouge1': 0.249585850179374, 'rouge2': 0.0966...  \n7                 29.444664  {'rouge1': 0.2642435855610533, 'rouge2': 0.105...  \n8                 29.444664  {'rouge1': 0.24632216278547844, 'rouge2': 0.08...  \n9                 29.444664  {'rouge1': 0.1126175778580799, 'rouge2': 0.020...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>bertscore_f1_mean</th>\n      <th>bertscore_f1_std</th>\n      <th>bertscore_precision_mean</th>\n      <th>bertscore_recall_mean</th>\n      <th>bleurt_f1_mean</th>\n      <th>bleurt_f1_std</th>\n      <th>frugalscore_f1_mean</th>\n      <th>frugalscore_f1_std</th>\n      <th>google_bleu</th>\n      <th>meteor</th>\n      <th>predicted_utterances_count</th>\n      <th>predicted_words_count_mean</th>\n      <th>predicted_words_count_std</th>\n      <th>reference_words_count_mean</th>\n      <th>reference_words_count_std</th>\n      <th>rouge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>finetuning/miti_alexander_street/meta-llama-Ll...</td>\n      <td>0.857203</td>\n      <td>0.043770</td>\n      <td>0.858164</td>\n      <td>0.857271</td>\n      <td>-0.963470</td>\n      <td>0.640698</td>\n      <td>0.006566</td>\n      <td>0.276434</td>\n      <td>{'google_bleu': 0.058391085206639076}</td>\n      <td>{'meteor': 0.2036675683351478}</td>\n      <td>6652</td>\n      <td>29.507817</td>\n      <td>33.912126</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.2286281584299184, 'rouge2': 0.076...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>finetuning/alexander_street_small/meta-llama-L...</td>\n      <td>0.846896</td>\n      <td>0.029539</td>\n      <td>0.853084</td>\n      <td>0.842088</td>\n      <td>-1.145407</td>\n      <td>0.485106</td>\n      <td>-0.098164</td>\n      <td>0.157977</td>\n      <td>{'google_bleu': 0.03455417966787487}</td>\n      <td>{'meteor': 0.1255303343638163}</td>\n      <td>6652</td>\n      <td>24.511876</td>\n      <td>35.467151</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.14487632150894864, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>finetuning/alexander_street_large/meta-llama-L...</td>\n      <td>0.848894</td>\n      <td>0.031134</td>\n      <td>0.858908</td>\n      <td>0.840558</td>\n      <td>-1.122640</td>\n      <td>0.513625</td>\n      <td>-0.097693</td>\n      <td>0.169693</td>\n      <td>{'google_bleu': 0.03292305001123111}</td>\n      <td>{'meteor': 0.11923888191444706}</td>\n      <td>6652</td>\n      <td>22.558178</td>\n      <td>33.688205</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1385491822036144, 'rouge2': 0.020...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>meta-llama/Llama-2-7b-chat-hf</td>\n      <td>0.810307</td>\n      <td>0.022486</td>\n      <td>0.781226</td>\n      <td>0.842561</td>\n      <td>-1.317601</td>\n      <td>0.441668</td>\n      <td>-0.094603</td>\n      <td>0.121680</td>\n      <td>{'google_bleu': 0.019129019671542388}</td>\n      <td>{'meteor': 0.1631574496909516}</td>\n      <td>6652</td>\n      <td>173.048256</td>\n      <td>33.08907</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.10993872775780206, 'rouge2': 0.01...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>finetuning/alexander_street_large/meta-llama-L...</td>\n      <td>0.846356</td>\n      <td>0.028436</td>\n      <td>0.853447</td>\n      <td>0.840669</td>\n      <td>-1.172437</td>\n      <td>0.484274</td>\n      <td>-0.104471</td>\n      <td>0.151046</td>\n      <td>{'google_bleu': 0.03286954239250308}</td>\n      <td>{'meteor': 0.11967210638136731}</td>\n      <td>6652</td>\n      <td>23.107637</td>\n      <td>32.997601</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.13922652976032834, 'rouge2': 0.02...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>finetuning/alexander_street_small/meta-llama-L...</td>\n      <td>0.846750</td>\n      <td>0.030293</td>\n      <td>0.852244</td>\n      <td>0.842509</td>\n      <td>-1.148234</td>\n      <td>0.494833</td>\n      <td>-0.093074</td>\n      <td>0.160853</td>\n      <td>{'google_bleu': 0.03529539773505573}</td>\n      <td>{'meteor': 0.12678145049351427}</td>\n      <td>6652</td>\n      <td>24.351022</td>\n      <td>33.650652</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1467090228221501, 'rouge2': 0.023...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>finetuning/miti_alexander_street/meta-llama-Ll...</td>\n      <td>0.861267</td>\n      <td>0.047765</td>\n      <td>0.864269</td>\n      <td>0.859231</td>\n      <td>-0.898174</td>\n      <td>0.691943</td>\n      <td>0.031425</td>\n      <td>0.310489</td>\n      <td>{'google_bleu': 0.07078532481310602}</td>\n      <td>{'meteor': 0.21671404789969428}</td>\n      <td>6652</td>\n      <td>24.929946</td>\n      <td>27.325215</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.249585850179374, 'rouge2': 0.0966...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>finetuning/miti/meta-llama-Llama-2-13b-chat-hf-6</td>\n      <td>0.862704</td>\n      <td>0.050348</td>\n      <td>0.865171</td>\n      <td>0.861135</td>\n      <td>-0.858924</td>\n      <td>0.718365</td>\n      <td>0.050345</td>\n      <td>0.323301</td>\n      <td>{'google_bleu': 0.06486506624350302}</td>\n      <td>{'meteor': 0.22925758259801637}</td>\n      <td>6652</td>\n      <td>25.274354</td>\n      <td>28.995102</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.2642435855610533, 'rouge2': 0.105...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>finetuning/miti/meta-llama-Llama-2-7b-chat-hf-6</td>\n      <td>0.858311</td>\n      <td>0.045633</td>\n      <td>0.858091</td>\n      <td>0.859440</td>\n      <td>-0.911828</td>\n      <td>0.670952</td>\n      <td>0.025398</td>\n      <td>0.292531</td>\n      <td>{'google_bleu': 0.05766905689656642}</td>\n      <td>{'meteor': 0.2225239151728812}</td>\n      <td>6652</td>\n      <td>33.305322</td>\n      <td>36.569563</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.24632216278547844, 'rouge2': 0.08...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>meta-llama/Llama-2-13b-chat-hf</td>\n      <td>0.804415</td>\n      <td>0.030133</td>\n      <td>0.774571</td>\n      <td>0.837792</td>\n      <td>-1.331038</td>\n      <td>0.416551</td>\n      <td>-0.106791</td>\n      <td>0.113936</td>\n      <td>{'google_bleu': 0.020428763345130177}</td>\n      <td>{'meteor': 0.16195078121252887}</td>\n      <td>6652</td>\n      <td>166.406194</td>\n      <td>43.370973</td>\n      <td>25.904991</td>\n      <td>29.444664</td>\n      <td>{'rouge1': 0.1126175778580799, 'rouge2': 0.020...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_no_arrays"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T17:44:01.111754Z",
     "start_time": "2024-02-13T17:44:01.087743600Z"
    }
   },
   "id": "f8415f085d52685d",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_df_no_arrays.to_csv('llama2_eval_no_arrays.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T17:44:23.699434Z",
     "start_time": "2024-02-13T17:44:23.686437300Z"
    }
   },
   "id": "3c77cb91908014cc",
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
